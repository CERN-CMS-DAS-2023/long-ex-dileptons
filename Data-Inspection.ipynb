{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "\n",
    "The first step of any analysis is to understand what we are searching for. In our analysis we aim to measure the central exclusive di-lepton production, $pp\\to p\\oplus \\ell\\ell \\oplus p$ process with $\\ell\\in\\{ e,\\mu \\} $. Feinman diagram of this process are shown bellow: \n",
    "\n",
    "<img src=\"img/diagrams.png\" alt=\"Feinmann diagrams\" style=\"width: 700px;\"/>\n",
    "\n",
    "Where in our case, we will consider only electrons and muons. \n",
    "\n",
    "---\n",
    "The measurement using 2016 data was published in [JHEP07(2018)153](https://arxiv.org/abs/1803.04496). This is the first time the 2017 data will be used to measure the central exclusive di-lepton production process at higher precision.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "<b>Remark</b>: Exclusive production of $\\tau$ leptons was not measured at the LHC yet since $\\tau$-leptons differ from electrons and muons by their relatively short lifetime ($c\\tau_0=87\\mu m$) and are observed only via their decay products. The main challenge with measuring $\\tau$s is elusive neutrinos (which escape detection). Hence measurement of the momentum of $\\tau$-lepton is tricky. Yet, it is possible because the opening angle between two daughter particles boosted with [lorentz factor](https://en.wikipedia.org/wiki/Lorentz_factor) $\\gamma$ is given by $\\theta ~\\sim 2/\\gamma$. With a large enough boost, the opening angle became collinear, and neutrino 4-momentum can be measured.\n",
    "\n",
    "To understand the process better, we will explore the final state signature. As we discussed earlier, samples are stored in the `h5py` data format, which can be easily accessed with Jupyter notebook. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with standard python imports\n",
    "#!pip install --user mplhep #enable this line if the import of mplhep fails\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make the plots in CMS style execute this line\n",
    "plt.style.use([hep.style.ROOT, hep.style.firamath])\n",
    "plt.style.use(hep.style.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute this line if running on SWAN, otherwise update the path to the data files:\n",
    "PATH='/eos/user/c/cmsdas/short-exercises/pps-protons-tutorial/data'\n",
    "#PATH='output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data (signal)\n",
    "\n",
    "We will load `h5py` files of the simulated signal events. Note that three different central exclusive di-lepton production processes are considered: exclusive, semi-exclusive, and inclusive (see Figure 1). We will load the files and convert them to pandas datafrme. Let's explore the differences between the processes.\n",
    "\n",
    "### Dataformat:\n",
    "\n",
    "We will use the following code `GetData(filename.h5)` to read the `h5` file and convert the data to pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetData(filename):\n",
    "    \n",
    "    \"\"\" opens a summary file and converts it to a pandas dataframe \"\"\"\n",
    "    \n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        dset = f['protons']\n",
    "        dset_columns = f['columns']\n",
    "        columns = list( dset_columns )\n",
    "        columns_str = [ item.decode(\"utf-8\") for item in columns ]\n",
    "        return pd.DataFrame( dset, columns=columns_str )\n",
    "    \n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the signal samples into the dataframes (takes some time)\n",
    "df_signal_excl = GetData(PATH+'/output-MC2017-Elastic-Non3+3-PreSel.h5')\n",
    "df_signal_semiexcl = GetData(PATH+'/output-MC2017-SingleDissociation-Non3+3-PreSel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data samples into the dataframes (takes some time)\n",
    "df_data={}\n",
    "eras=['B']\n",
    "#eras=['B','C1','E','F1'] #uncooment to process all data\n",
    "for x in eras:\n",
    "    df_data[x] = GetData(PATH+'/output-UL2017{}-PreSel.h5'.format(x))\n",
    "    df_data[x]['era']=x\n",
    "    print('output-UL2017{}-PreSel shape = {}'.format(x,df_data[x].shape))\n",
    "\n",
    "#combine all into a single one\n",
    "df_data=pd.concat([df_data[x] for x in eras])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data files\n",
    "\n",
    "Similarly to what we did with ROOT files in the short exercise, let's look at the info we have in the dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintInfoFromDF(df):\n",
    "    print('Print all branches:')\n",
    "    print(df.keys())\n",
    "    print('Size of the data is ',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PrintInfoFromDF(df_signal_excl)\n",
    "PrintInfoFromDF(df_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have 38 different columns and 212744 raws in the file (each raw corresponds to a different event). In data we have added an extra column to flag which data-taking era is the event comming from.\n",
    "\n",
    "**TASK 1**\n",
    "\n",
    "Look at distributions of different kinematic variables (among different processes) and try to see if you observe any difference... The code below `PlotFromDF(variable, dataframes, labels)` will plot normalized shapes of selected variables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotFromDF(variable, xmin, xmax, nbins, dataframes, _labels, ax, log=False):\n",
    "    bins = np.linspace(xmin,xmax,nbins)\n",
    "    data=[]; labels=[]\n",
    "    for df, label in zip(dataframes, _labels):\n",
    "        h, _ = np.histogram(df[variable], bins,density=True)\n",
    "        data.append(h)\n",
    "        labels.append(label)\n",
    "    hep.histplot(data, bins, ax=ax, label=labels)\n",
    "    hep.cms.label(data=True, paper=False, year='2017', ax=ax)\n",
    "    ax.legend(); \n",
    "    ax.set(xlabel=variable, ylabel='p.d.f.')\n",
    "    if log: plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, we will plot the di-lepton [acoplanarity](https://en.wikipedia.org/wiki/Acoplanarity) defined by:\n",
    "$$A = 1 - \\Delta\\phi(\\mu,\\mu)/\\pi$$\n",
    "\n",
    "In the exclusive events, due to absence of additional radiation, both leptons expected to be produced back-to-back, or with $\\Delta\\phi(\\mu,\\mu)\\sim\\pi$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be plotting MC prediction with the data, where the data is mostly populated with background events\n",
    "procc = [df_signal_excl,df_signal_semiexcl,df_data]\n",
    "labels = ['Exclusive dilep','Semi-exclusive dilep','data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "PlotFromDF('Acopl',0,1,100,procc,labels, ax, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f, ax = plt.subplots()\n",
    "#PlotFromDF('ExtraPfCands',0,20,20,procc,labels, ax, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f, ax = plt.subplots()\n",
    "#PlotFromDF('InvMass',0,800,100,procc,labels, ax, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagged protons\n",
    "\n",
    "In central exclusive events, the tagged protons' momentum loss corresponds to the 4-momentum of the interacting photons. From proton momentum loss, denoted by $\\xi=1-\\Delta p/p$, we can reconstruct two quantities of the central system - the mass and the rapidity:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "m_{\\ell\\ell} &= \\sqrt{s\\xi_1\\xi_2}\\\\\n",
    "Y_{\\ell\\ell} &= \\frac{1}{2}\\log(\\xi_1/\\xi_2),\n",
    "\\end{split}\\label{eq:eq1}\n",
    "\\end{equation}\n",
    "In case of single dissociation (when only one proton remains intact), we can reconstruct proton momentum loss from the kinematics measured in the central detector: di-lepton mass $m_{\\ell\\ell}$ and pseudo-rapidity of the leptons $\\eta_{\\ell\\pm}$, using the following formula:\n",
    "\n",
    "\\begin{equation}\n",
    "\\xi_\\pm = \\frac{1}{\\sqrt{s}}[p_T(\\ell+)e^{\\pm\\eta(\\ell+)} + p_T(\\ell-)e^{\\pm\\eta(\\ell-)}] \n",
    "\\label{eq:eq2}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "In the next block we will inspect this correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>TASK 2</b>\n",
    "\n",
    "Write a function that will produce a 2D scatter plot of measured $\\xi$ in the forward detector and the reconstructed $\\xi(\\ell\\ell)$ using the second formula above.\n",
    "\n",
    "\n",
    "HINT: Use the block below to add a new column to the dataframe with reconstructed $\\xi$ named `recXi_pos` and `recXi_neg`\n",
    "```python\n",
    "df_signal['recXi_pos'] = USE FORMULA (2) TO COMPUTE NEGATIVE AND POSSITIVE XIs\n",
    "df_signal['recXi_neg'] = USE FORMULA (2) TO COMPUTE NEGATIVE AND POSSITIVE XIs\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ComputeXi(dataframe):\n",
    "    \n",
    "    \"\"\" computes the proton csi based on the central system kinematics\"\"\"\n",
    "    \n",
    "    dataframe['recXi_pos'] = dataframe['XiMuMuPlus'] # USE FORMULA (2) TO COMPUTE NEGATIVE AND POSSITIVE XIs\n",
    "    dataframe['recXi_neg'] = dataframe['XiMuMuMinus'] # USE FORMULA (2) TO COMPUTE NEGATIVE AND POSSITIVE XIs\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "#if you are stuck uncomment the following line to load the solution\n",
    "#%load ./snippets/DataInspectionTask2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below `Plot2DScatter(dataframe)` will plot 2D scatter plot between reconstructed $\\xi$ from the two leptons and $\\xi$ measured by the forward detectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot2DScatter(dataframe, mask = [], proton_selection = \"MultiRP\"):\n",
    "\n",
    "    \"\"\"Shows the corelation between the xi reconstucted from the PPS system and from the central dilepton system\"\"\"\n",
    "    \n",
    "    if not mask.empty and len(mask) != dataframe.shape[0]:\n",
    "        print('Error: bad mask, check if the mask corresponds to the dataframe')\n",
    "        return\n",
    "    \n",
    "    if proton_selection == \"SingleRP\":\n",
    "        # Single-RP in pixel stations\n",
    "        msk1 = mask & ( dataframe[\"MultiRP\"] == 0) & ( dataframe[\"RPId1\"] == 23 )\n",
    "        msk2 = mask & ( dataframe[\"MultiRP\"] == 0) & ( dataframe[\"RPId1\"] == 123 )\n",
    "    elif proton_selection == \"MultiRP\":\n",
    "        # Multi-RP\n",
    "        msk1 = mask & ( dataframe[\"MultiRP\"] == 1 ) & ( dataframe[\"Arm\"] == 0 )\n",
    "        msk2 = mask & ( dataframe[\"MultiRP\"] == 1 ) & ( dataframe[\"Arm\"] == 1 )\n",
    " \n",
    "    print ( len(dataframe[ \"Xi\" ][ msk1 ]), len(dataframe[ \"Xi\" ][ msk2 ]) )\n",
    "\n",
    "    fig, axes = plt.subplots( 2, 2, figsize=(20,20) )\n",
    "    axes[0,0].plot( dataframe[ \"Xi\" ][ msk1 ], dataframe[ \"recXi_pos\" ][ msk1 ], 'ko' )\n",
    "    axes[0,1].plot( dataframe[ \"Xi\" ][ msk2 ], dataframe[ \"recXi_neg\" ][ msk2 ], 'ko' )\n",
    "    _,_,_, im = axes[1,0].hist2d( dataframe[ \"Xi\" ][ msk1 ], dataframe[ \"recXi_pos\" ][ msk1 ], bins=(50,50), norm=LogNorm(), cmap='viridis' )\n",
    "    fig.colorbar(im, ax=axes[1,0])\n",
    "    _,_,_, im = axes[1,1].hist2d( dataframe[ \"Xi\" ][ msk2 ], dataframe[ \"recXi_neg\" ][ msk2 ], bins=(50,50), norm=LogNorm(), cmap='viridis' )\n",
    "    fig.colorbar(im, ax=axes[1,1])\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            #aux lines\n",
    "            axes[i,j].plot( (0.,0.15), (0.,0.15), 'k--', linewidth=1 )\n",
    "            axes[i,j].plot( (0.,0.15), (0.,0.90*0.15), 'k:', linewidth=1 )\n",
    "            axes[i,j].plot( (0.,0.15), (0.,1.10*0.15), 'k:', linewidth=1 )\n",
    "            axes[i,j].set_xlim(0.,0.15)\n",
    "            axes[i,j].set_ylim(0.,0.15)\n",
    "            sgn='+' if j==0 else '-'\n",
    "            axes[i,j].set_xlabel(r'$\\xi_{%s}$ (PPS)'%(sgn))\n",
    "            axes[i,j].set_ylabel(r'$\\xi_{%s}$ (dileptons)'%(sgn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation plots - signal:\n",
    "\n",
    "Check your results with ploting correlation plots for the signal (exclusive) events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before the start, lets mask events with high invariant mass, with two leptons produced back to back exclusivelly \n",
    "df_signal = df_signal_excl\n",
    "msk_excl = ( df_signal[\"InvMass\"] >= 110. ) & ( df_signal[\"Acopl\"] <= 0.009 ) & ( df_signal[\"ExtraPfCands\"] <= 1 )\n",
    "\n",
    "#in addiitonl we will focus only on MultiRP reconstruction\n",
    "proton_selection = \"MultiRP\" # \"SingleRP\" or \"MultiRP\"\n",
    "\n",
    "#compute xi\n",
    "ComputeXi(df_signal)\n",
    "\n",
    "#plot correlations:\n",
    "Plot2DScatter(df_signal, mask=msk_excl, proton_selection=proton_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the difference betweeen recontructed and measured $\\xi$ values in 1D plot. It is easier to mask only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new variables to dataframes for possitivle and negative xi's :\n",
    "mask_pos = msk_excl & ( df_signal[\"MultiRP\"] == 1 ) & ( df_signal[\"Arm\"] == 0 )\n",
    "mask_neg = msk_excl & ( df_signal[\"MultiRP\"] == 1 ) & ( df_signal[\"Arm\"] == 1 )\n",
    "\n",
    "df_signal['delxi_pos'] = (1 - df_signal[ \"Xi\" ] / df_signal[ \"recXi_pos\" ])\n",
    "df_signal['delxi_neg'] = (1 - df_signal[ \"Xi\" ] / df_signal[ \"recXi_neg\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( 1, 2, figsize=(20,10) )\n",
    "PlotFromDF('delxi_pos',-5,3,100,[df_signal[ mask_pos ]],['exclusive di-$\\ell$'],axes[0], log=False)\n",
    "PlotFromDF('delxi_neg',-5,3,100,[df_signal[ mask_neg ]],['exclusive di-$\\ell$'],axes[1], log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation plots - data:\n",
    "\n",
    "<b>TASK 3</b>\n",
    "\n",
    "Produce correlation plots now for data events as we did for the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#MASK EVENTS WITH TWO LEPTONS PRODUCED BACK TO BACK EXCLUSEVILY\n",
    "msk_data = ( df_data[\"InvMass\"] >= 110. ) & ( df_data[\"Acopl\"] <= 0.009 ) & ( df_data[\"ExtraPfCands\"] <= 1 )\n",
    "\n",
    "#in addiitonl we will focus only on MultiRP reconstruction\n",
    "proton_selection = \"MultiRP\" # \"SingleRP\" or \"MultiRP\"\n",
    "\n",
    "#compute xi\n",
    "ComputeXi(df_data)\n",
    "\n",
    "#plot correlations:\n",
    "Plot2DScatter(df_data, mask=msk_data, proton_selection=proton_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare data to signal + background\n",
    "\n",
    "In the following we'll use the data as a background (assuming we haven't yet selected any signal candidate).\n",
    "We'll make a plot of the difference between the $\\xi$ reconstructed from PPS and the one reconstructed from the dilepton system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkg = df_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots( 1, 2, figsize=(20,10) )\n",
    "\n",
    "bins_ = 40\n",
    "range_ = (-5.,3.)\n",
    "resample_factor = 680\n",
    "\n",
    "\n",
    "counts={}\n",
    "errors={}\n",
    "for arm in [0,1]:\n",
    "\n",
    "    xi_dil='XiMuMuPlus' if arm==0 else 'XiMuMuMinus'\n",
    "    \n",
    "    #build the differences for the data\n",
    "    msk_data_arm = msk_data & ( df_data[\"MultiRP\"] == 1 ) & ( df_data[\"Arm\"] == arm )\n",
    "    delta = ( 1. - df_data[ \"Xi\" ][ msk_data_arm ] / df_data[ xi_dil ][ msk_data_arm ] )\n",
    "    counts[arm], bin_edges = np.histogram( delta, bins=bins_, range=range_ )\n",
    "    errors[arm] = np.sqrt( counts[arm] )\n",
    "    bin_centers = ( bin_edges[:-1] + bin_edges[1:] ) / 2.\n",
    "    axes[arm].errorbar(bin_centers, counts[arm], yerr=errors[arm], fmt='o', label='Data')\n",
    "        \n",
    "    print('Arm=',arm,'Data counts=',counts[arm], 'bin edges=',bin_edges )\n",
    "\n",
    "    #build the differences for the background\n",
    "    msk_bkg = ( df_bkg[\"MultiRP\"] == 1 ) & ( df_bkg[\"Arm\"] == arm )\n",
    "    weights = None\n",
    "    if resample_factor > 1:\n",
    "        weights = np.full_like( df_bkg[ \"Xi\" ][ msk_bkg ], ( 1./resample_factor ) )\n",
    "    delta_bkg = ( 1. - df_bkg[ \"Xi\" ][ msk_bkg ] / df_bkg[ xi_dil ][ msk_bkg ] )\n",
    "    axes[arm].hist( delta_bkg, bins=bins_, range=range_, weights=weights, label='Background' )\n",
    "\n",
    "    \n",
    "#final tweak to have both y-axis at the same scale showing all data\n",
    "total_counts=np.concatenate( [counts[0],counts[1]] )\n",
    "total_errors=np.concatenate( [errors[0], errors[1]] )\n",
    "idx_ymax_ = np.argmax( total_counts )\n",
    "y_max = total_counts[idx_ymax_] + 2*total_errors[idx_ymax_]\n",
    "print ( \"y max. = {}\".format(y_max) )\n",
    "for arm in [0,1]:\n",
    "    axes[arm].set_ylim( top=y_max )\n",
    "    sgn='+' if arm==0 else '-'\n",
    "    axes[arm].set_xlabel(r'$[\\Delta\\xi/\\xi(\\ell\\ell)]_{%s}$'%(sgn))\n",
    "    axes[arm].set_ylabel('Events')\n",
    "    axes[arm].legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ancillary variables\n",
    "\n",
    "In the following we plot ancillary variables, e.g. $\\theta_y$, applying a cut on the resolution of the reconstructed $\\xi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotAncillary(data, bkg, var='ThY', rangeDelta=(-0.20,0.20), bins=10, xran=(-0.005,0.005) ):\n",
    "    \n",
    "    \"\"\" compares data and background for the variable var applying a cut on the relative resolution defined by rangeDelta \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots( 1, 2, figsize=(20,10) )\n",
    "\n",
    "    \n",
    "    counts={}\n",
    "    errors={}\n",
    "    for arm in [0,1]:\n",
    "    \n",
    "        xi_dil='XiMuMuPlus' if arm==0 else 'XiMuMuMinus'\n",
    "    \n",
    "        #mask the data to be plotted\n",
    "        msk_data_arm = msk_data & ( data[\"MultiRP\"] == 1 ) & ( data[\"Arm\"] == arm )\n",
    "        delta = ( 1. - data[ \"Xi\" ][ msk_data_arm ] / data[ xi_dil ][ msk_data_arm ] )\n",
    "        msk_data_delta = (delta>=rangeDelta[0]) & (delta<=rangeDelta[1])\n",
    "        counts[arm], bin_edges = np.histogram( data[var][msk_data_arm][msk_data_delta], bins=bins, range=xran )\n",
    "        errors[arm] = np.sqrt( counts[arm] )\n",
    "        bin_centres = ( bin_edges[:-1] + bin_edges[1:] ) / 2.\n",
    "        axes[arm].errorbar(bin_centres, counts[arm], yerr=errors[arm], fmt='o',label='Data')\n",
    "        \n",
    "        print('Arm=',arm,'Data counts=',counts, 'bin edges=',bin_edges )\n",
    "\n",
    "        #mask the background\n",
    "        msk_bkg = ( bkg[\"MultiRP\"] == 1 ) & ( bkg[\"Arm\"] == arm )\n",
    "        weights = None\n",
    "        if resample_factor > 1:\n",
    "            weights = np.full_like( bkg[ var ][ msk_bkg ], ( 1./resample_factor ) )\n",
    "       \n",
    "        vals_bkg = bkg[msk_bkg]\n",
    "        delta_bkg = ( 1. - vals_bkg[ \"Xi\" ] / vals_bkg[xi_dil ] )\n",
    "        msk_bkg_delta = (delta_bkg>=rangeDelta[0]) & (delta_bkg<=rangeDelta[1])\n",
    "            \n",
    "        axes[arm].hist( vals_bkg[var][msk_bkg_delta], bins=bins, range=xran, weights=weights[msk_bkg_delta], label='Background' )\n",
    "\n",
    "    #final tweak to have both y-axis at the same scale showing all data\n",
    "    total_counts=np.concatenate( [counts[0],counts[1]] )\n",
    "    total_errors=np.concatenate( [errors[0], errors[1]] )\n",
    "    idx_ymax_ = np.argmax( total_counts )\n",
    "    y_max = total_counts[idx_ymax_] + 2*total_errors[idx_ymax_]\n",
    "    print ( \"y max. = {}\".format(y_max) )\n",
    "    for arm in [0,1]:\n",
    "        axes[arm].set_ylim( top=y_max )\n",
    "        sgn='+' if arm==0 else '-'\n",
    "        axes[arm].set_xlabel(var)\n",
    "        axes[arm].set_ylabel('Events')\n",
    "        axes[arm].legend(loc='best')\n",
    "    \n",
    "\n",
    "deltaXi_cut=(-0.20,0.20)\n",
    "#plotAncillary(df_data,df_bkg, var='Xi',  rangeDelta=deltaXi_cut ,bins=10,xran=(0.,0.2))\n",
    "#plotAncillary(df_data,df_bkg, var='ThX', rangeDelta=deltaXi_cut ,bins=10,xran=(-0.0005,0.0005))\n",
    "plotAncillary(df_data,df_bkg, var='ThY', rangeDelta=deltaXi_cut ,bins=10,xran=(-0.005,0.005))\n",
    "#plotAncillary(df_data,df_bkg, var='T',   rangeDelta=deltaXi_cut ,bins=10,xran=(-4,0))\n",
    "#plotAncillary(df_data,df_bkg, var='Time',rangeDelta=deltaXi_cut ,bins=10,xran=(-0.5,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
